{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcbab0ff6ac960e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T05:23:03.845571800Z",
     "start_time": "2025-01-30T05:23:03.837845800Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_gridworld():\n",
    "    \"\"\"\n",
    "    (0,0)을 왼쪽 아래로 놓고,\n",
    "    rows=4, cols=4 크기의 격자를 예로 들어 설명합니다.\n",
    "    \n",
    "    - start_state = (0,0)\n",
    "    - blocked = (1,1)\n",
    "    - terminal_plus = (3,3)   # +1 보상\n",
    "    - terminal_minus = (2,3)  # -1 보상\n",
    "    \n",
    "    U=(+1,0), D=(-1,0), L=(0,-1), R=(0,+1) 로 이동.\n",
    "    \"\"\"\n",
    "    rows, cols = 3, 4\n",
    "\n",
    "    # 관심 위치들\n",
    "    start_state = (0, 0)\n",
    "    blocked = (1, 1)\n",
    "    terminal_plus = (2, 3)\n",
    "    terminal_minus = (1, 3)\n",
    "\n",
    "    # 가능한 행동\n",
    "    actions = ['U', 'D', 'L', 'R']\n",
    "\n",
    "    # (행 변화, 열 변화)\n",
    "    moves = {\n",
    "        'U': (1, 0),  # 위로\n",
    "        'D': (-1, 0),  # 아래로\n",
    "        'L': (0, -1),  # 왼쪽\n",
    "        'R': (0, 1)  # 오른쪽\n",
    "    }\n",
    "\n",
    "    # 격자 범위 체크용\n",
    "    def in_bounds(r, c):\n",
    "        return 0 <= r < rows and 0 <= c < cols\n",
    "\n",
    "    # 상태 집합(막힌 칸 제외)\n",
    "    states = []\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (r, c) == blocked:\n",
    "                continue\n",
    "            states.append((r, c))\n",
    "\n",
    "    # 전이 모델 P[s][a] = [(prob, next_state, reward), ... ]\n",
    "    P = {}\n",
    "\n",
    "    for s in states:\n",
    "        P[s] = {}\n",
    "\n",
    "        # 터미널 상태 체크\n",
    "        if s == terminal_plus:\n",
    "            P[s]['terminal'] = True\n",
    "            for a in actions:\n",
    "                # 이미 종료된 상태이므로 자기 자신으로 이동, 보상 0\n",
    "                P[s][a] = [(1.0, s, 0)]\n",
    "            continue\n",
    "        elif s == terminal_minus:\n",
    "            P[s]['terminal'] = True\n",
    "            for a in actions:\n",
    "                P[s][a] = [(1.0, s, 0)]\n",
    "            continue\n",
    "        else:\n",
    "            P[s]['terminal'] = False\n",
    "\n",
    "        # 일반 상태의 경우\n",
    "        for a in actions:\n",
    "            dr, dc = moves[a]\n",
    "            nr, nc = s[0] + dr, s[1] + dc\n",
    "\n",
    "            # 범위 내인지 및 막힌 칸 아닌지 확인\n",
    "            if in_bounds(nr, nc) and (nr, nc) != blocked:\n",
    "                # 터미널 칸에 도달하는 경우 보상 부여\n",
    "                if (nr, nc) == terminal_plus:\n",
    "                    reward = 1.0\n",
    "                elif (nr, nc) == terminal_minus:\n",
    "                    reward = -1.0\n",
    "                else:\n",
    "                    reward = 0.0\n",
    "                next_s = (nr, nc)\n",
    "            else:\n",
    "                # 이동 불가능하면 제자리 머무르기, 보상 0\n",
    "                next_s = s\n",
    "                reward = 0.0\n",
    "\n",
    "            P[s][a] = [(1.0, next_s, reward)]\n",
    "\n",
    "    return states, actions, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8367c61be1aed65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T05:23:03.855375Z",
     "start_time": "2025-01-30T05:23:03.847589400Z"
    }
   },
   "outputs": [],
   "source": [
    "def value_iteration(states, actions, P, gamma=0.9, theta=1e-6):\n",
    "    \"\"\"\n",
    "    Value Iteration 알고리즘을 이용해 V(s)를 추정하고\n",
    "    결정론적 정책 pi(s)를 반환한다.\n",
    "    \"\"\"\n",
    "    # 1. V(s) 초기화\n",
    "    V = {s: 0.0 for s in states}\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "        # 2. 모든 상태 s에 대해 갱신\n",
    "        for s in states:\n",
    "            # 터미널 상태라면 업데이트 생략하고 그대로 둠\n",
    "            if P[s].get(\"terminal\", False):\n",
    "                continue\n",
    "\n",
    "            v_old = V[s]\n",
    "\n",
    "            # 가능한 모든 행동에 대한 Q(s,a)를 계산한 뒤 그 중 최댓값으로 갱신\n",
    "            action_values = []\n",
    "            for a in actions:\n",
    "                q_value = 0.0\n",
    "                for (prob, s_next, reward) in P[s][a]:\n",
    "                    q_value += prob * (reward + gamma * V[s_next])\n",
    "                action_values.append(q_value)\n",
    "\n",
    "            V[s] = max(action_values) if action_values else v_old\n",
    "            delta = max(delta, abs(v_old - V[s]))\n",
    "\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    # 3. 결정론적 정책 도출\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        if P[s].get(\"terminal\", False):\n",
    "            policy[s] = None  # 터미널 상태에는 정책 정의 X\n",
    "            continue\n",
    "\n",
    "        best_a, best_q = None, float('-inf')\n",
    "        for a in actions:\n",
    "            q_value = 0.0\n",
    "            for (prob, s_next, reward) in P[s][a]:\n",
    "                q_value += prob * (reward + gamma * V[s_next])\n",
    "            if q_value > best_q:\n",
    "                best_q = q_value\n",
    "                best_a = a\n",
    "        policy[s] = best_a\n",
    "\n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab571d48c42e6a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T05:23:03.871469300Z",
     "start_time": "2025-01-30T05:23:03.856405900Z"
    }
   },
   "outputs": [],
   "source": [
    "states, actions, Q_table = build_gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f20c0dfe8eaa450",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T05:23:03.884404100Z",
     "start_time": "2025-01-30T05:23:03.865364600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 0),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b103d44ec6f01afd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T05:23:03.896134300Z",
     "start_time": "2025-01-30T05:23:03.881403400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U', 'D', 'L', 'R']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c334618b36b6d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T05:23:03.931754900Z",
     "start_time": "2025-01-30T05:23:03.890106300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): {'terminal': False,\n",
       "  'U': [(1.0, (1, 0), 0.0)],\n",
       "  'D': [(1.0, (0, 0), 0.0)],\n",
       "  'L': [(1.0, (0, 0), 0.0)],\n",
       "  'R': [(1.0, (0, 1), 0.0)]},\n",
       " (0, 1): {'terminal': False,\n",
       "  'U': [(1.0, (0, 1), 0.0)],\n",
       "  'D': [(1.0, (0, 1), 0.0)],\n",
       "  'L': [(1.0, (0, 0), 0.0)],\n",
       "  'R': [(1.0, (0, 2), 0.0)]},\n",
       " (0, 2): {'terminal': False,\n",
       "  'U': [(1.0, (1, 2), 0.0)],\n",
       "  'D': [(1.0, (0, 2), 0.0)],\n",
       "  'L': [(1.0, (0, 1), 0.0)],\n",
       "  'R': [(1.0, (0, 3), 0.0)]},\n",
       " (0, 3): {'terminal': False,\n",
       "  'U': [(1.0, (1, 3), -1.0)],\n",
       "  'D': [(1.0, (0, 3), 0.0)],\n",
       "  'L': [(1.0, (0, 2), 0.0)],\n",
       "  'R': [(1.0, (0, 3), 0.0)]},\n",
       " (1, 0): {'terminal': False,\n",
       "  'U': [(1.0, (2, 0), 0.0)],\n",
       "  'D': [(1.0, (0, 0), 0.0)],\n",
       "  'L': [(1.0, (1, 0), 0.0)],\n",
       "  'R': [(1.0, (1, 0), 0.0)]},\n",
       " (1, 2): {'terminal': False,\n",
       "  'U': [(1.0, (2, 2), 0.0)],\n",
       "  'D': [(1.0, (0, 2), 0.0)],\n",
       "  'L': [(1.0, (1, 2), 0.0)],\n",
       "  'R': [(1.0, (1, 3), -1.0)]},\n",
       " (1, 3): {'terminal': True,\n",
       "  'U': [(1.0, (1, 3), 0)],\n",
       "  'D': [(1.0, (1, 3), 0)],\n",
       "  'L': [(1.0, (1, 3), 0)],\n",
       "  'R': [(1.0, (1, 3), 0)]},\n",
       " (2, 0): {'terminal': False,\n",
       "  'U': [(1.0, (2, 0), 0.0)],\n",
       "  'D': [(1.0, (1, 0), 0.0)],\n",
       "  'L': [(1.0, (2, 0), 0.0)],\n",
       "  'R': [(1.0, (2, 1), 0.0)]},\n",
       " (2, 1): {'terminal': False,\n",
       "  'U': [(1.0, (2, 1), 0.0)],\n",
       "  'D': [(1.0, (2, 1), 0.0)],\n",
       "  'L': [(1.0, (2, 0), 0.0)],\n",
       "  'R': [(1.0, (2, 2), 0.0)]},\n",
       " (2, 2): {'terminal': False,\n",
       "  'U': [(1.0, (2, 2), 0.0)],\n",
       "  'D': [(1.0, (1, 2), 0.0)],\n",
       "  'L': [(1.0, (2, 1), 0.0)],\n",
       "  'R': [(1.0, (2, 3), 1.0)]},\n",
       " (2, 3): {'terminal': True,\n",
       "  'U': [(1.0, (2, 3), 0)],\n",
       "  'D': [(1.0, (2, 3), 0)],\n",
       "  'L': [(1.0, (2, 3), 0)],\n",
       "  'R': [(1.0, (2, 3), 0)]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ba9621909c037d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T05:23:03.932755500Z",
     "start_time": "2025-01-30T05:23:03.905121900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 도출된 정책(pi) ==\n",
      "π((0, 0)) = U\n",
      "π((0, 1)) = R\n",
      "π((0, 2)) = U\n",
      "π((0, 3)) = L\n",
      "π((1, 0)) = U\n",
      "π((1, 2)) = U\n",
      "π((1, 3)) = None\n",
      "π((2, 0)) = R\n",
      "π((2, 1)) = R\n",
      "π((2, 2)) = R\n",
      "π((2, 3)) = None\n",
      "\n",
      "== 최종 가치 함수(V) ==\n",
      "V((0, 0)) = 0.6561\n",
      "V((0, 1)) = 0.7290\n",
      "V((0, 2)) = 0.8100\n",
      "V((0, 3)) = 0.7290\n",
      "V((1, 0)) = 0.7290\n",
      "V((1, 2)) = 0.9000\n",
      "V((1, 3)) = 0.0000\n",
      "V((2, 0)) = 0.8100\n",
      "V((2, 1)) = 0.9000\n",
      "V((2, 2)) = 1.0000\n",
      "V((2, 3)) = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Value Iteration 적용\n",
    "V, policy = value_iteration(states, actions, Q_table)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"== 도출된 정책(pi) ==\")\n",
    "for s in sorted(policy):\n",
    "    print(f\"π({s}) = {policy[s]}\")\n",
    "\n",
    "print(\"\\n== 최종 가치 함수(V) ==\")\n",
    "for s in sorted(V):\n",
    "    print(f\"V({s}) = {V[s]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
