{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8aa563bbb499c0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T12:27:02.212615800Z",
     "start_time": "2025-02-01T12:27:02.204262900Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_gridworld():\n",
    "    \"\"\"\n",
    "    (0,0)을 왼쪽 아래로 놓고,\n",
    "    rows=4, cols=4 크기의 격자를 예로 들어 설명합니다.\n",
    "    \n",
    "    - start_state = (0,0)\n",
    "    - blocked = (1,1)\n",
    "    - terminal_plus = (3,3)   # +1 보상\n",
    "    - terminal_minus = (2,3)  # -1 보상\n",
    "    \n",
    "    U=(+1,0), D=(-1,0), L=(0,-1), R=(0,+1) 로 이동.\n",
    "    \"\"\"\n",
    "    rows, cols = 3, 4\n",
    "\n",
    "    # 관심 위치들\n",
    "    start_state = (0, 0)\n",
    "    blocked = (1, 1)\n",
    "    terminal_plus = (2, 3)\n",
    "    terminal_minus = (1, 3)\n",
    "\n",
    "    # 가능한 행동\n",
    "    actions = ['U', 'D', 'L', 'R']\n",
    "\n",
    "    # (행 변화, 열 변화)\n",
    "    moves = {\n",
    "        'U': (1, 0),  # 위로\n",
    "        'D': (-1, 0),  # 아래로\n",
    "        'L': (0, -1),  # 왼쪽\n",
    "        'R': (0, 1)  # 오른쪽\n",
    "    }\n",
    "\n",
    "    # 격자 범위 체크용\n",
    "    def in_bounds(r, c):\n",
    "        return 0 <= r < rows and 0 <= c < cols\n",
    "\n",
    "    # 상태 집합(막힌 칸 제외)\n",
    "    states = []\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if (r, c) == blocked:\n",
    "                continue\n",
    "            states.append((r, c))\n",
    "\n",
    "    # 전이 모델 P[s][a] = [(prob, next_state, reward), ... ]\n",
    "    P = {}\n",
    "\n",
    "    for s in states:\n",
    "        P[s] = {}\n",
    "\n",
    "        # 터미널 상태 체크\n",
    "        if s == terminal_plus:\n",
    "            P[s]['terminal'] = True\n",
    "            for a in actions:\n",
    "                # 이미 종료된 상태이므로 자기 자신으로 이동, 보상 0\n",
    "                P[s][a] = [(1.0, s, 0)]\n",
    "            continue\n",
    "        elif s == terminal_minus:\n",
    "            P[s]['terminal'] = True\n",
    "            for a in actions:\n",
    "                P[s][a] = [(1.0, s, 0)]\n",
    "            continue\n",
    "        else:\n",
    "            P[s]['terminal'] = False\n",
    "\n",
    "        # 일반 상태의 경우\n",
    "        for a in actions:\n",
    "            dr, dc = moves[a]\n",
    "            nr, nc = s[0] + dr, s[1] + dc\n",
    "\n",
    "            # 범위 내인지 및 막힌 칸 아닌지 확인\n",
    "            if in_bounds(nr, nc) and (nr, nc) != blocked:\n",
    "                # 터미널 칸에 도달하는 경우 보상 부여\n",
    "                if (nr, nc) == terminal_plus:\n",
    "                    reward = 1.0\n",
    "                elif (nr, nc) == terminal_minus:\n",
    "                    reward = -1.0\n",
    "                else:\n",
    "                    reward = 0.0\n",
    "                next_s = (nr, nc)\n",
    "            else:\n",
    "                # 이동 불가능하면 제자리 머무르기, 보상 0\n",
    "                next_s = s\n",
    "                reward = 0.0\n",
    "\n",
    "            P[s][a] = [(1.0, next_s, reward)]\n",
    "\n",
    "    return states, actions, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5fc56c7492c5a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T12:27:02.227385300Z",
     "start_time": "2025-02-01T12:27:02.214616400Z"
    }
   },
   "outputs": [],
   "source": [
    "def policy_iteration(states, actions, P, gamma=0.9, theta=1e-6):\n",
    "    # 1. 정책과 가치 함수를 임의로 초기화\n",
    "    policy = {}\n",
    "    V = {}\n",
    "    for s in states:\n",
    "        if P[s].get(\"terminal\", False):\n",
    "            policy[s] = None\n",
    "        else:\n",
    "            policy[s] = actions[0]  # 임의로 첫 번째 행동으로 초기화\n",
    "        V[s] = 0.0\n",
    "\n",
    "    while True:\n",
    "        # ---------- 2. Policy Evaluation (정책 평가 단계) ----------\n",
    "        while True:\n",
    "            delta = 0.0\n",
    "            for s in states:\n",
    "                # 터미널 상태면 업데이트하지 않음\n",
    "                if P[s].get(\"terminal\", False):\n",
    "                    continue\n",
    "\n",
    "                v_old = V[s]\n",
    "                # 현재 정책이 선택한 행동\n",
    "                a = policy[s]\n",
    "\n",
    "                # V(s) <- Σ p(s', r | s, a) [ r + gamma * V(s') ]\n",
    "                v_new = 0.0\n",
    "                for (prob, s_next, reward) in P[s][a]:\n",
    "                    v_new += prob * (reward + gamma * V[s_next])\n",
    "\n",
    "                V[s] = v_new\n",
    "                delta = max(delta, abs(v_old - v_new))\n",
    "\n",
    "            # 정책 평가 수렴 검사\n",
    "            if delta < theta:\n",
    "                break\n",
    "\n",
    "        # ---------- 3. Policy Improvement (정책 개선 단계) ----------\n",
    "        policy_stable = True\n",
    "        for s in states:\n",
    "            if P[s].get(\"terminal\", False):\n",
    "                continue\n",
    "\n",
    "            old_action = policy[s]\n",
    "\n",
    "            # 모든 행동 a에 대한 Q(s,a) 계산\n",
    "            best_action = None\n",
    "            best_q = float(\"-inf\")\n",
    "            for a in actions:\n",
    "                q_val = 0.0\n",
    "                for (prob, s_next, reward) in P[s][a]:\n",
    "                    q_val += prob * (reward + gamma * V[s_next])\n",
    "                if q_val > best_q:\n",
    "                    best_q = q_val\n",
    "                    best_action = a\n",
    "\n",
    "            # 정책을 최적 행동으로 갱신\n",
    "            policy[s] = best_action\n",
    "\n",
    "            # 만약 정책이 바뀌었다면 아직 안정되지 않은 것\n",
    "            if best_action != old_action:\n",
    "                policy_stable = False\n",
    "\n",
    "        # 정책이 안정되었다면 종료\n",
    "        if policy_stable:\n",
    "            break\n",
    "\n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c8a4fe6612f8d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T12:27:02.230779300Z",
     "start_time": "2025-02-01T12:27:02.222384500Z"
    }
   },
   "outputs": [],
   "source": [
    "states, actions, Q_table = build_gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50fe5ba9d0814a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T12:27:02.247276300Z",
     "start_time": "2025-02-01T12:27:02.232822100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (1, 0),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8c57ef30030b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T12:27:02.258729600Z",
     "start_time": "2025-02-01T12:27:02.247779200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U', 'D', 'L', 'R']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8309babbb4ab7683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T12:27:02.290850400Z",
     "start_time": "2025-02-01T12:27:02.259729300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): {'terminal': False,\n",
       "  'U': [(1.0, (1, 0), 0.0)],\n",
       "  'D': [(1.0, (0, 0), 0.0)],\n",
       "  'L': [(1.0, (0, 0), 0.0)],\n",
       "  'R': [(1.0, (0, 1), 0.0)]},\n",
       " (0, 1): {'terminal': False,\n",
       "  'U': [(1.0, (0, 1), 0.0)],\n",
       "  'D': [(1.0, (0, 1), 0.0)],\n",
       "  'L': [(1.0, (0, 0), 0.0)],\n",
       "  'R': [(1.0, (0, 2), 0.0)]},\n",
       " (0, 2): {'terminal': False,\n",
       "  'U': [(1.0, (1, 2), 0.0)],\n",
       "  'D': [(1.0, (0, 2), 0.0)],\n",
       "  'L': [(1.0, (0, 1), 0.0)],\n",
       "  'R': [(1.0, (0, 3), 0.0)]},\n",
       " (0, 3): {'terminal': False,\n",
       "  'U': [(1.0, (1, 3), -1.0)],\n",
       "  'D': [(1.0, (0, 3), 0.0)],\n",
       "  'L': [(1.0, (0, 2), 0.0)],\n",
       "  'R': [(1.0, (0, 3), 0.0)]},\n",
       " (1, 0): {'terminal': False,\n",
       "  'U': [(1.0, (2, 0), 0.0)],\n",
       "  'D': [(1.0, (0, 0), 0.0)],\n",
       "  'L': [(1.0, (1, 0), 0.0)],\n",
       "  'R': [(1.0, (1, 0), 0.0)]},\n",
       " (1, 2): {'terminal': False,\n",
       "  'U': [(1.0, (2, 2), 0.0)],\n",
       "  'D': [(1.0, (0, 2), 0.0)],\n",
       "  'L': [(1.0, (1, 2), 0.0)],\n",
       "  'R': [(1.0, (1, 3), -1.0)]},\n",
       " (1, 3): {'terminal': True,\n",
       "  'U': [(1.0, (1, 3), 0)],\n",
       "  'D': [(1.0, (1, 3), 0)],\n",
       "  'L': [(1.0, (1, 3), 0)],\n",
       "  'R': [(1.0, (1, 3), 0)]},\n",
       " (2, 0): {'terminal': False,\n",
       "  'U': [(1.0, (2, 0), 0.0)],\n",
       "  'D': [(1.0, (1, 0), 0.0)],\n",
       "  'L': [(1.0, (2, 0), 0.0)],\n",
       "  'R': [(1.0, (2, 1), 0.0)]},\n",
       " (2, 1): {'terminal': False,\n",
       "  'U': [(1.0, (2, 1), 0.0)],\n",
       "  'D': [(1.0, (2, 1), 0.0)],\n",
       "  'L': [(1.0, (2, 0), 0.0)],\n",
       "  'R': [(1.0, (2, 2), 0.0)]},\n",
       " (2, 2): {'terminal': False,\n",
       "  'U': [(1.0, (2, 2), 0.0)],\n",
       "  'D': [(1.0, (1, 2), 0.0)],\n",
       "  'L': [(1.0, (2, 1), 0.0)],\n",
       "  'R': [(1.0, (2, 3), 1.0)]},\n",
       " (2, 3): {'terminal': True,\n",
       "  'U': [(1.0, (2, 3), 0)],\n",
       "  'D': [(1.0, (2, 3), 0)],\n",
       "  'L': [(1.0, (2, 3), 0)],\n",
       "  'R': [(1.0, (2, 3), 0)]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "963175d3e6b9717e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T12:27:02.290850400Z",
     "start_time": "2025-02-01T12:27:02.272400300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 최종 정책 ===\n",
      "π((0, 0)) = U\n",
      "π((0, 1)) = R\n",
      "π((0, 2)) = U\n",
      "π((0, 3)) = L\n",
      "π((1, 0)) = U\n",
      "π((1, 2)) = U\n",
      "π((1, 3)) = None\n",
      "π((2, 0)) = R\n",
      "π((2, 1)) = R\n",
      "π((2, 2)) = R\n",
      "π((2, 3)) = None\n",
      "\n",
      "=== 최종 가치 함수 ===\n",
      "V((0, 0)) = 0.6561\n",
      "V((0, 1)) = 0.7290\n",
      "V((0, 2)) = 0.8100\n",
      "V((0, 3)) = 0.7290\n",
      "V((1, 0)) = 0.7290\n",
      "V((1, 2)) = 0.9000\n",
      "V((1, 3)) = 0.0000\n",
      "V((2, 0)) = 0.8100\n",
      "V((2, 1)) = 0.9000\n",
      "V((2, 2)) = 1.0000\n",
      "V((2, 3)) = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Policy Iteration 실행\n",
    "V_star, pi_star = policy_iteration(states, actions, Q_table)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== 최종 정책 ===\")\n",
    "for s in sorted(pi_star):\n",
    "    print(f\"π({s}) = {pi_star[s]}\")\n",
    "\n",
    "print(\"\\n=== 최종 가치 함수 ===\")\n",
    "for s in sorted(V_star):\n",
    "    print(f\"V({s}) = {V_star[s]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
